# -*- coding: utf-8 -*-
"""AI_BREAST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/136HkBv8Oq02yaHVjkVIqCCbEIiSGNpY1

**Dataset Metadata:**

Data Source Location: Baheya Hospital for Early Detection & Treatment of Women's Cancer, Cairo, Egypt.
Data Accessibility: Dataset Link
Related Research Article: Walid Al-Dhabyani, Mohammed Gomaa, Hussien Khaled, and Aly Fahmy, "Deep Learning Approaches for Data Augmentation and Classification of Breast Masses using Ultrasound Images" [1]
Overview:


**Data Collection:** The dataset includes breast ultrasound images collected from 600 female patients aged between 25 and 75 years old in 2018.
Image Characteristics:
Number of Images: 780
Format: PNG
Average Image Size: 500 Ã— 500 pixels

**Image Categories:**
Normal: 133 images
Benign: 487 images
Malignant: 210 images
Total: 780 images


Ground Truth (Mask Images): Each image in the dataset has its own ground truth, or mask image.



**Value of the Data:**
Ultrasound scans are commonly used for breast cancer examination and early detection, as they are considered safe compared to other radiology imaging techniques.
The dataset can be used to train machine learning models for classifying, detecting, and segmenting early signs of masses or micro-calcifications in breast cancer.
Researchers interested in breast cancer classification, detection, and segmentation can utilize this dataset, possibly combining it with others for further analysis.
Comprehensive dataset containing breast cancer states (normal, benign, and malignant).
This dataset is the first publicly available breast ultrasound dataset, to the best of the authors' knowledge.
"""

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'breast-ultrasound-images-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1209633%2F2021025%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240228%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240228T161014Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D14e905afc1ca75b1bea82e109095e3a8eb8ef087c9906453d43ca2770c030709bec72458cbc37e531f20c74741a55bbd89afc97ef86f8d2d3a5e9ff36fc6f8e0070ebeb94ba94af9e4be2d36336f1919e0191523858cf3825a288c6213bdf11dc7657af3d627e565e05a6cd01a67d945a59b7835edb675c2dbb4260f646ca7017240953327a7547087f21c81884d07873afc0f0cc995e88c042f7eed59e7750aa47a5d79d69ca7c849a1c977d9970e6cf08fb1d55c49e1bf1c8327214d848149117996d5928846bf45c1c57166c2865a634a8ac3d448f165409b93b56a3fcd18caf4b8e64e52572f0df9b856520d8ba70602677a40437908acb07f066a955e5d'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.applications import EfficientNetV2B1
from tensorflow.keras.applications import EfficientNetB1
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import regularizers
from keras.callbacks import EarlyStopping
from sklearn.metrics import classification_report, accuracy_score
import random

#Data Preprocessing:
import os
import cv2
from PIL import Image

image_directory = "../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/"

def load_images(image_folder, label_value):
    images = [img for img in os.listdir(image_directory + image_folder)]
    for image_name in images:
        if image_name.split('.')[1] == 'png' and '_mask' not in image_name:
            image = cv2.imread(image_directory + image_folder + image_name)
            if image is not None:
                image = Image.fromarray(image, 'RGB')
                image = image.resize((SIZE, SIZE))
                image = np.array(image)
                dataset.append(image)
                label.append(label_value)

SIZE = 224
dataset = []
label = []

load_images('benign/', 0)  # Benign class with label 0
load_images('malignant/', 1)  # Malignant class with label 1
load_images('normal/', 2)  # Normal class with label 2

# Convert dataset and label to numpy arrays
dataset = np.array(dataset)
label = np.array(label)
print("Dataset shape:", dataset.shape)
print("Label shape:", label.shape)

# Convert dataset and label to numpy arrays
dataset = np.array(dataset)
label = np.array(label)

# Split the dataset into train and test sets
from sklearn.model_selection import train_test_split

num_samples, height, width, channels = dataset.shape
X_flat = dataset.reshape(num_samples, -1)  # Reshape to (samples, height*width*channels)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_flat, label, test_size=0.25, random_state=42)

#Applying different augmentation settings to minority classes:
augmentation_class1 = ImageDataGenerator(
    #rescale=1./255,
    rotation_range=5,  # Rotate images by a maximum of 10 degrees
    width_shift_range=0.1,  # Shift images horizontally by 10% of the width
    height_shift_range=0.1,  # Shift images vertically by 10% of the height
    zoom_range=0.1,  # Zoom images by 10%
    horizontal_flip=True,  # Flip images horizontally
    vertical_flip=False  # No vertical flipping
)
augmentation_class2 = ImageDataGenerator(
    rotation_range=30,  # Rotate images by a maximum of 10 degrees
    width_shift_range=0.2,  # Shift images horizontally by 10% of the width
    height_shift_range=0.2,  # Shift images vertically by 10% of the height
    zoom_range=0.2,  # Zoom images by 10%
    horizontal_flip=True,  # Flip images horizontally
    vertical_flip=True
)

X_train = X_train.reshape(-1, 224, 224, 3)  # Reshape your input data to match the expected input shape

datagen = ImageDataGenerator(
    horizontal_flip=True,   # Flip images horizontally
    vertical_flip=True,     # Flip images vertically
    fill_mode='nearest'     # Fill in missing pixels using the nearest available
)
datagen.fit(X_train)
augmented_images = []
augmented_labels = []

# Number of times to augment the data (in this case, we'll double the dataset)
augmentation_factor = 4

for x_batch, y_batch in datagen.flow(X_train, y_train, batch_size=len(X_train), shuffle=False):
    augmented_images.append(x_batch)
    augmented_labels.append(y_batch)
    if len(augmented_images) >= augmentation_factor:
        break

# Concatenate the augmented data batches
X_train = np.concatenate(augmented_images)
y_train = np.concatenate(augmented_labels)

# Verify the shape of augmented data
print("Shape of augmented images:", X_train.shape)
print("Shape of augmented labels:", y_train.shape)

def apply_augmentation(X_train, y_train):
    if y_train == 1:  # Check for class 1
        return augmentation_class1.random_transform(X_train), y_train
    if y_train == 2:
        return augmentation_class2.random_transform(X_train), y_train
    else:
        return X_train, y_train
X_test= X_test.reshape(-1, 224, 224, 3)  # Reshape your input data to match the expected input shape



from sklearn.utils.class_weight import compute_class_weight
class_labels = np.unique(y_train)
class_weights = compute_class_weight('balanced', classes=class_labels, y=y_train)
class_weight = {i: class_weights[i] for i in range(len(class_weights))}

base_model =EfficientNetV2B1(weights='imagenet', include_top=False,
                            input_shape=(224, 224, 3))

# Add custom top layers for your 3-class classification with regularization and dropout
model = Sequential()
model.add(base_model)
model.add(GlobalAveragePooling2D())
model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))
model.add(Dropout(0.5))
model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))
model.add(Dropout(0.2))
model.add(Dense(3, activation='softmax'))

# Freeze layers from the pre-trained model
for layer in base_model.layers[-20:]:  # Unfreeze last 20 layers for fine-tuning
    layer.trainable = True


# Compile the model with a lower learning rate and different optimizer
model.compile(optimizer=Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model with data augmentation and the modified architecture
history = model.fit(X_train,y_train,class_weight=class_weight, epochs=20,
                    validation_data=(X_test,y_test))

# Evaluate model accuracy on test data
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_accuracy}")

# Predict classes for test data using model.predict
y_pred_probs = model.predict(X_test)
y_pred_classes = np.argmax(y_pred_probs, axis=1)

# Generate and print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred_classes))

# Generate and print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_classes))

import matplotlib.pyplot as plt
# Plot training and validation accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Print best accuracy achieved during training
best_training_accuracy = max(history.history['accuracy'])
print("Best Training Accuracy: ", best_training_accuracy,"\n")

# Print approximate accuracy (validation accuracy)
approximate_accuracy = history.history['val_accuracy'][-1]
print("Approximate Accuracy (Validation Accuracy):", approximate_accuracy,"\n")

# Print top validation accuracy
top_validation_accuracy = max(history.history['val_accuracy'])
print("Top Validation Accuracy:", top_validation_accuracy,"\n")

from tensorflow.keras.models import load_model

# Assuming 'model' is your trained model
model.save('final_model.h5')

import math
from tensorflow.keras.models import load_model
# Load the saved model
model = load_model('final_model.h5')
import matplotlib.pyplot as plt
import math

def predict_and_show_random_images(model, dataset, true_labels, images_to_show=20, images_per_row=5):
    num_images = len(dataset)
    random_indices = np.random.choice(num_images, size=images_to_show, replace=False)
    num_rows = math.ceil(images_to_show / images_per_row)

    for i in range(num_rows):
        fig, axes = plt.subplots(1, images_per_row, figsize=(20, 4))

        for j in range(images_per_row):
            index = i * images_per_row + j

            if index < images_to_show:
                dataset_index = random_indices[index]
                # Expand dimensions to match model input shape
                image = np.expand_dims(dataset[dataset_index], axis=0)

                # Predict the class probabilities
                class_probabilities = model.predict(image)

                # Get the predicted class label
                predicted_class = np.argmax(class_probabilities)

                # Define class labels (you may need to adjust these according to your dataset)
                class_labels = ['benign', 'malignant', 'normal']

                # Display the image
                axes[j].imshow(image.squeeze())  # Squeeze to remove the batch dimension
                axes[j].axis('off')
                axes[j].set_title('True Label: {}\nPredicted Label: {}'.format(class_labels[true_labels[dataset_index]], class_labels[predicted_class]))

        plt.tight_layout()
        plt.show()

predict_and_show_random_images(model, dataset,label, images_to_show=20, images_per_row=5)

